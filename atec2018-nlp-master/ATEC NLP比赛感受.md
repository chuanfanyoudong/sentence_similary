# ATEC NLP比赛总结

今年5月份报名了蚂蚁金服的比赛，有金融大脑和风险大脑两个赛题，金融大脑主要解决智能客服遇到的自然语言处理问题，对于两个语句，判断是否是同一个意思，帮助构建客服的专用问答库，比赛的评判标准是f1分数，这对于正负样本不平衡问题比准确率更好，风险大脑则是通过用户登录和交易信息判断此次交易是否存在风险，在网络安全形势严峻的今天，其重要意义不言而喻。

2个月时间的投入，还是有一些收获：

- 对keras的使用更加熟练，尤其是Callback的使用，

- 阅读了pytorch的文档，初学使用pytorch，其特点为：
  1. 强化版的numpy，前向运算和操作与numpy非常相似，而且可以直接利用GPU的运算能力。
  2. 与TensorFlow不同的是，pytorch无需编译图，每次backward都会根据当前运算过程构造新的图，然后销毁，在程序中甚至可以通过条件语句直接改变图的运行流程，启用或停止相关节点。
  3. pytorch对于最新研究成果的跟踪实现比keras快得多，拥有更丰富的神经网络层，更多优化器等。

- 学习了基于pytorch的fastai框架，框架的作者Jeremy Howard是Kaggle高手，fastai框架吸收了一些Keras中便于使用的特性，整个框架源码约4000余行，短小精悍，使用方便

- 跟着fastai的源码实践了统一语言模型精调(ULMFiT)方法，在文本相似度任务上并未取得好结果，ULMFiT方法特点如下：
  1. 训练一个语言模型，模型架构为Embedding + 三层双向LSTM(+dropout)，数据集一般为wiki，受限于数据加载和预处理方式，目前的源码仅能处理不超过500M的语料。
  2. 在当前任务语料上finetune语言模型。
  3. 根据当前任务设计分类器模块，其出入为语言模型最后一个LSTM层的输出，从最后一层开始，逐层unfreeze，进行分类器模型精调。

- 学习了batchsize参数对训练的影响，更大的batchsize意味着更准确的梯度方向，可以更快完成每个epoch，同时也意味着每个epoch的更新次数更少，需要更多的epoch才能使模型收敛，一味增大batchsize反而会延长训练时间。

- 学会使用循环学习率变化的训练技巧，Circular Learning Rate通过循环改变学习率，从小到大，从大到小，不断循环，使模型更容易跳出局部最优，做出更多的尝试，该方法确实调高了模型训练的结果。

- 学会使用SWA(stochastic weights averaging)模型融合方法，即将训练过程中的模型权重进行平均达到模型融合的目的，该方法的代价极小，仅需要保存另一份模型权重在内存或GPU显存中，在每个epoch后(或其他间隔)更新一次该权重，在训练结束时便可获得一个普通模型和一个SWA模型，该方法提高了5/7模型在初赛数据上的泛化能力，但并未提高任何模型对于5倍的复赛数据的泛化能力，这可能与模型训练不够充分有关。

- 学习了一些模型融合方法，包括求多模型平均、投票、Stacking和Blending模型融合方法，其中Quora比赛中的一个stacking方案值得借鉴，他们将训练数据分成5份，三份训练，1份验证，1份测试，轮番5次，直到每份数据都参与1次验证和1次测试，这比传统的stacking更好的利用了数据。

- 学习了语句对任务建模的两类基本模型，分别是向量表征模型和表征交互模型，向量表征模型利用孪生网络(Siamese Network)将两个语句编码成两个独立的向量，然后计算向量间的相似度，比如Siamese Net，DSSM；表征交互模型通过构造一个相关性交互矩阵，将两个语句的信息进行糅合处理，比如Decomposable Attention，ESIM。

- 除了ESIM外，其他人用了两个新模型DRCN和DIIN     (DRCN是SNLI排行榜最佳模型）

- 本次比赛未尝试的方法：
  - 利用句子的拼音作为辅助输入，通过拼音embedding加强模型，
  - 将字、词和拼音等混入一个模型中，增强单个模型的能力
  - DRCN模型
  - **10折验证训练模型（大伙都在用）**


> 其他两个队的开源代码
> [复赛0.7368_红鲤鱼绿鲤鱼与驴](https://github.com/raven4752/huabei)
> [复赛0.7352_World2vec](https://github.com/amxineohp/atec_2018_nlp)

> 经验分享
> [逼格learning](https://openclub.alipay.com/read.php?tid=9074&fid=96)

> 语句对任务模型排行榜[SNLI项目](https://nlp.stanford.edu/projects/snli)

